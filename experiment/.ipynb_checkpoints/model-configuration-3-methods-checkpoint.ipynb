{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-number/3.jpg\n",
      "/kaggle/input/catfiles-1/images\n",
      "/kaggle/input/catfiles/cat.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.callbacks import History as history\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 2\n"
     ]
    }
   ],
   "source": [
    "min=1\n",
    "max=2\n",
    "print(min,\"-\",max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一种方法Sequential API 这种比较常用\n",
    "https://note.nkmk.me/python-tensorflow-keras-basics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.Sequential is keras.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.Sequential is Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "0 9\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(y_train.min(),y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model_configuration\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_input_shape (Flatten (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,Activation\n",
    "\n",
    "model=Sequential(name=\"test_model_configuration\")\n",
    "model.add(Flatten(input_shape=(28,28),name='flatten_input_shape'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=[callbacks.EarlyStopping(patience=2,restore_best_weights=True),\n",
    "          callbacks.ModelCheckpoint(\n",
    "                 'mnist_sequential_{epoch:03d}_{val_loss:.4f}.h5',\n",
    "                 save_best_only=True\n",
    "             )\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.9059 - accuracy: 0.7038 - val_loss: 0.5444 - val_accuracy: 0.8623\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6885 - accuracy: 0.8150 - val_loss: 0.4351 - val_accuracy: 0.8878\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5593 - accuracy: 0.8474 - val_loss: 0.3526 - val_accuracy: 0.9046\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4890 - accuracy: 0.8663 - val_loss: 0.3176 - val_accuracy: 0.9182\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4650 - accuracy: 0.8756 - val_loss: 0.3025 - val_accuracy: 0.9262\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=5,validation_split=0.2,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb\tmnist_sequential_003_0.3526.h5\r\n",
      "mnist_sequential_001_0.5444.h5\tmnist_sequential_004_0.3176.h5\r\n",
      "mnist_sequential_002_0.4351.h5\tmnist_sequential_005_0.3025.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.callbacks.History'>\n"
     ]
    }
   ],
   "source": [
    "print(type(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.9059176445007324,\n",
       "  0.6884852647781372,\n",
       "  0.5592852234840393,\n",
       "  0.4890369176864624,\n",
       "  0.4649748206138611],\n",
       " 'accuracy': [0.7038333415985107,\n",
       "  0.8149999976158142,\n",
       "  0.8473541736602783,\n",
       "  0.8662916421890259,\n",
       "  0.8756250143051147],\n",
       " 'val_loss': [0.5443525314331055,\n",
       "  0.4351227879524231,\n",
       "  0.3526466190814972,\n",
       "  0.3176186680793762,\n",
       "  0.302533358335495],\n",
       " 'val_accuracy': [0.862333357334137,\n",
       "  0.8878333568572998,\n",
       "  0.9045833349227905,\n",
       "  0.9181666374206543,\n",
       "  0.9262499809265137]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.862333357334137,\n",
       " 0.8878333568572998,\n",
       " 0.9045833349227905,\n",
       " 0.9181666374206543,\n",
       " 0.9262499809265137]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=history.history['val_accuracy']\n",
    "x=[1,2,3,4,5]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,color='b',linestyle=':',marker = 'o',markerfacecolor='r',markersize = 10)\n",
    "plt.xlabel(\"Run Epoch Times\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Result\")\n",
    "plt.grid(True)\n",
    "# plt.text(0,0,'Mark')\n",
    "# plt.annotate('focus',xy=(-5,0),xytext=(-2,0.25),arrowprops = dict(facecolor='red',shrink=0.05,headlength= 20,headwidth = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.9230\n"
     ]
    }
   ],
   "source": [
    "pred=model.evaluate(x_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルの評価: Model.evaluate()  使用test测试数据进行测试，使用evaluate\n",
    "### 学習済みモデルを使った予測（推論）: Model.predict()  如果想要进行图片测试使用predict，只输入test图片，不需要正解标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(type(predicts))\n",
    "print(len(predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0098240e-32 2.9751243e-16 2.1233276e-20 2.8305411e-12 0.0000000e+00\n",
      " 1.5660722e-37 0.0000000e+00 1.0000000e+00 0.0000000e+00 2.5756149e-20]\n",
      "1.0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(predicts[0])\n",
    "print(predicts[0].sum())\n",
    "print(predicts[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将每一行输出结果都找到最大的输出值并返回result\n",
    "result=predicts.argmax(axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二种Subclassing API（Model Subclassing）这种也经常使用\n",
    "https://note.nkmk.me/python-tensorflow-keras-basics/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用一种变形的subclassing 方式编写model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 3.0123 - accuracy: 0.7305 - val_loss: 0.5812 - val_accuracy: 0.8574\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6701 - accuracy: 0.8235 - val_loss: 0.3729 - val_accuracy: 0.9048\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5596 - accuracy: 0.8544 - val_loss: 0.3518 - val_accuracy: 0.9224\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4851 - accuracy: 0.8747 - val_loss: 0.3136 - val_accuracy: 0.9300\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4570 - accuracy: 0.8805 - val_loss: 0.2731 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f703c184590>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "\n",
    "def create_model():\n",
    "    model=Sequential(name=\"create_model\")\n",
    "#     由于输入图片是灰阶色只有一维，所以是28*28，如果是普通彩色图片应该使用input_shape=(28,28,3)\n",
    "#     model.add(Flatten(input_shape=(28,28,3)))\n",
    "    model.add(Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10,activation=\"softmax\"))\n",
    "    return model\n",
    "    \n",
    "model=create_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "callback=[callbacks.EarlyStopping(patience=2,restore_best_weights=True),\n",
    "          callbacks.ModelCheckpoint(\n",
    "                 'mnist_sequential_{epoch:03d}_{val_loss:.4f}.h5',\n",
    "                 save_best_only=True\n",
    "             )\n",
    "          ]\n",
    "\n",
    "model.fit(x_train,y_train,epochs=5,validation_split=0.2,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"create_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               301184    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 302,474\n",
      "Trainable params: 302,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32011568546295166, 0.9304999709129333]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 8, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pred.argmax(axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb\tmnist_sequential_003_0.3674.h5\r\n",
      "mnist_sequential_001_0.5444.h5\tmnist_sequential_004_0.3057.h5\r\n",
      "mnist_sequential_001_0.5791.h5\tmnist_sequential_004_0.3176.h5\r\n",
      "mnist_sequential_002_0.4305.h5\tmnist_sequential_005_0.3025.h5\r\n",
      "mnist_sequential_002_0.4351.h5\tmodel.h5\r\n",
      "mnist_sequential_003_0.3526.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "model=load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"create_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 压缩文件处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "68608000/68606236 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    fname='cats_and_dogs_filtered.zip',\n",
    "    origin='https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip',\n",
    "    extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.keras/datasets\n",
      "/root/.keras/datasets/cats_and_dogs_filtered\n"
     ]
    }
   ],
   "source": [
    "print(os.path.dirname(path_to_zip))\n",
    "path_to_dir = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "print(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(path_to_dir, 'train')\n",
    "test_dir = os.path.join(path_to_dir, 'validation')\n",
    "len(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片读取，改变尺寸，数组化,画像前处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "import tensorflow.keras.applications.vgg16 as vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAoWVYSWZJSSoACAAAAAUAEgEDAAEAAAABAAAAMQECABUAAABKAAAAMgECABQAAABfAAAAEwIDAAEAAAABAAAAaYcEAAEAAABzAAAAAAAAAEFDRCBTeXN0ZW1zIMr9wuuzyc/xADIwMjA6MTE6MTIgMTU6MTc6MjAAAwCQkgIABAAAADkyMwACoAQAAQAAAKQAAAADoAQAAQAAAMgAAAAAAAAAAAAAAOTVkxkAAADUSURBVHic7ZRLDsMwCESLIfe/bwxDF0hR5ET401TdlFUk4DnAALn762krjxP/0N9BzazWug5V1avImFlEiGgQSgs6VVURSQJWesrMecAcNMra9z0PmyufaCh+dPoNUVWzt/OXw1tKiY+zAJLEbIiBY+bIBzDYq0757n5UWkppXCICYBqaGBHVWqPdz0DNLHZs27art9PTq0VbzSwRwPSaEhGA/A7M/emn4m+qc/dDW+vQ8x0SEXe/HfR9bu4GAOD2yCbWX9Px23xYR6cLxD50zb4CfQNsZobJlNB+mgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F70901AE150>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一张图片读取，并显示\n",
    "img_pil = image.load_img(\n",
    "    '/kaggle/input/digit-number/3.jpg', target_size=(28, 28)\n",
    ")\n",
    "img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# 图片格式显示，并转化成多维数组\n",
    "print(type(img_pil))\n",
    "# <class 'PIL.Image.Image'>\n",
    "\n",
    "img = image.img_to_array(img_pil)\n",
    "print(type(img))\n",
    "# <class 'numpy.ndarray'>\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0UlEQVR4nGNgGDaAEc5iUYzmYWBYd+0DpiL9skN///79+/fv9QAMubRjf5/OVhQR0ar5/X0Rmpz9m8+ZbBBm5t8vxqiSn/7WwZisx/96wNhMDAwMDAy8DF9gAr9/oluZ7iAMYyp/ecyDzVsMDAwMDPV/O3HKVfztY8Yl5/r3qjROfc+2y+CQElvwawtOMw/9Pe8voABhC+kzIAc8b28CMwPDG6YvrAwMT3dkcvIyMLDAJS2SWy8yMDB88mDiPljN91sYxVAWFQSfn0FcBZflAwkAy2k7NgRbuiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F705817E210>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# 打开一张图片\n",
    "# im=Image.open('/kaggle/input/digit-number/3.jpg')\n",
    "# im.show()\n",
    "# 把一个多维数组变成图片\n",
    "im=Image.fromarray(x_test[77])\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=x_test[77]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の前処理: preprocess_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "# print(img)\n",
    "img.max(),img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prepro=vgg16.preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-123.68, 255.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img_prepro.shape)\n",
    "# print(img_prepro)\n",
    "img_prepro.min(),img_prepro.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import io, color\n",
    "\n",
    "# lina_color = io.imread(path+img)\n",
    "# 将图片维度从3D变成2D（灰色）\n",
    "img_gray = color.rgb2gray(img)\n",
    "img_gray=np.expand_dims(img_gray,axis=0)\n",
    "img_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(img_gray)\n",
    "result=pred.argmax()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上面的直接使用predict产生了正确的结果2，下面使用vgg16的preprocess_input预处理图片，产生了错误的结果8，结论：不应该使用不相关model的前处理\n",
    "# 前处理需要相同类别的图片才能有效果，实际使用的图片是手写数字，vgg16没有相关性，不应该使用\n",
    "img_pre_proc=vgg16.preprocess_input(img_gray)\n",
    "pred1=model.predict(img_pre_proc)\n",
    "result=pred1.argmax()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
